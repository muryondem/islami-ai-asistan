# -*- coding: utf-8 -*-
import streamlit as st
import os
import json
import math
import base64
from google import genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from gtts import gTTS

# ==========================================
# AYARLAR & API (DOKUNULMADI)
# ==========================================
API_ANAHTARIM = st.secrets["GEMINI_API_KEY"]
VERITABANI_YOLU = "./veritabanÄ±"
POPULER_SORULAR_DOSYASI = "populer_sorular.json"
GUNCEL_MODEL = "gemini-2.0-flash"
client = genai.Client(api_key=API_ANAHTARIM)

# ==========================================
# FONKSÄ°YONLAR (HAFIZA VE REFERANS KORUNDU)
# ==========================================
def populer_sorulari_getir():
    if os.path.exists(POPULER_SORULAR_DOSYASI):
        with open(POPULER_SORULAR_DOSYASI, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

@st.cache_resource
def kaynaklari_yukle():
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=API_ANAHTARIM)
    v_db = Chroma(persist_directory=VERITABANI_YOLU, embedding_function=embeddings) if os.path.exists(VERITABANI_YOLU) else None
    return v_db, embeddings

vector_db, embeddings_model = kaynaklari_yukle()

def metni_seslendir(metin, dil='tr'):
    try:
        tts = gTTS(text=metin.replace("*", ""), lang=dil, slow=False)
        tts.save("temp_voice.mp3")
        with open("temp_voice.mp3", "rb") as f:
            b64 = base64.b64encode(f.read()).decode()
            return f'<audio controls autoplay><source src="data:audio/mp3;base64,{b64}" type="audio/mp3"></audio>'
    except: return ""

# ==========================================
# CSS (KESÄ°N BÃ–LÃœNMÃœÅ EKRAN TASARIMI)
# ==========================================
st.set_page_config(page_title="MUIN", page_icon="ğŸŒ™", layout="wide") # GeniÅŸ mod daha ferah olur

st.markdown("""
    <style>
    /* SayfanÄ±n genel kaymasÄ±nÄ± engelle */
    html, body, [data-testid="stAppViewContainer"] {
        overflow: hidden !important;
        background-color: #000000;
    }

    /* Ãœst Alan: PopÃ¼ler Sorular (Dinamik YÃ¼kseklik) */
    .top-panel {
        background-color: #000000;
        border-bottom: 2px solid #333;
        padding: 10px;
        margin-bottom: 10px;
    }

    /* Alt Alan: Chat (Sabit YÃ¼kseklik ve KaydÄ±rÄ±labilir) */
    .chat-scroll {
        overflow-y: auto;
        height: 60vh; /* EkranÄ±n %60'Ä± chat alanÄ± */
        padding: 10px;
        border: 1px solid #222;
        border-radius: 10px;
    }

    .stChatMessage { border-radius: 15px; background-color: #1A1A1A !important; }
    .stButton>button { border-radius: 15px; background-color: #1A1A1A; border: 1px solid #444; color: white !important; font-size: 12px; }
    
    /* Soru GiriÅŸ AlanÄ±nÄ± Sabitle */
    [data-testid="stChatInput"] {
        position: fixed;
        bottom: 20px;
        z-index: 9999;
    }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 1. BÃ–LGE: ÃœST (ESNEK POPÃœLER SORULAR)
# ==========================================
top_container = st.container()
with top_container:
    st.title("ğŸŒ™ MUIN")
    populer_listesi = populer_sorulari_getir()
    if "clicked_q" not in st.session_state: st.session_state.clicked_q = None

    if populer_listesi:
        st.markdown("##### ğŸŒŸ PopÃ¼ler Sorular")
        
        # Ä°lk 10 soruyu gÃ¶ster
        ana_sorular = populer_listesi[:10]
        c1, c2, c3 = st.columns(3) # 3 sÃ¼tun yaparak alanÄ± daha iyi kullanÄ±yoruz
        for i, k in enumerate(ana_sorular):
            col = [c1, c2, c3][i % 3]
            with col:
                if st.button(f"ğŸ” {k['soru']}", key=f"top_{i}", use_container_width=True):
                    st.session_state.clicked_q = k['soru']
        
        # 10'dan fazla varsa "Daha Fazla" expander iÃ§ine al
        if len(populer_listesi) > 10:
            with st.expander("â• Daha Fazla PopÃ¼ler Soru GÃ¶r"):
                d1, d2, d3 = st.columns(3)
                for i, k in enumerate(populer_listesi[10:30]): # 30'a kadar destekle
                    col = [d1, d2, d3][i % 3]
                    with col:
                        if st.button(f"ğŸ” {k['soru']}", key=f"extra_{i}", use_container_width=True):
                            st.session_state.clicked_q = k['soru']

st.divider()

# ==========================================
# 2. BÃ–LGE: ALT (KAYDIRILABÄ°LÄ°R CHAT)
# ==========================================
# Container height kullanÄ±mÄ± en gÃ¼venli bÃ¶lÃ¼nmÃ¼ÅŸ ekran yÃ¶ntemidir
chat_area = st.container(height=450) # BurasÄ± kendi iÃ§inde kayar

if "messages" not in st.session_state: st.session_state.messages = []

with chat_area:
    for i, m in enumerate(st.session_state.messages):
        with st.chat_message(m["role"]):
            st.markdown(m["content"])
            if m["role"] == "assistant" and st.button("ğŸ”Š Dinle", key=f"voice_{i}"):
                st.markdown(metni_seslendir(m["content"]), unsafe_allow_html=True)

# ==========================================
# 3. BÃ–LGE: GÄ°RDÄ° VE ZEKA
# ==========================================
u_input = st.chat_input("Sorunuzu buraya yazÄ±n...")
prompt = st.session_state.clicked_q if st.session_state.clicked_q else u_input
st.session_state.clicked_q = None

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    current_prompt = st.session_state.messages[-1]["content"]
    
    with chat_area:
        with st.chat_message("assistant"):
            with st.spinner("MUIN mÃ¼talaa ediyor..."):
                try:
                    # HAFIZA: Son konuÅŸmalarÄ± hatÄ±rla
                    gecmis = st.session_state.messages[-6:-1]
                    gecmis_text = "\n".join([f"{m['role']}: {m['content']}" for m in gecmis])

                    # RAG: Kaynaklardan bul
                    if vector_db:
                        docs = vector_db.similarity_search(current_prompt, k=6)
                        baglam = "\n\n".join([f"ğŸ“š Kaynak: {os.path.basename(d.metadata['source'])}\n{d.page_content}" for d in docs])
                    else: baglam = "Belge bulunamadÄ±."

                    # MUIN KÄ°MLÄ°ÄÄ° VE PROMPT
                    system_msg = (
                        "Sen bilge, nazik ve Ã¶ÄŸretici bir muallim olan MUIN'sin. "
                        "CevaplarÄ±na baÅŸlarken her seferinde farklÄ± olacak ÅŸekilde; 'SelamÃ¼naleykÃ¼m kÄ±ymetli kardeÅŸim', 'Aziz dostum merhaba', "
                        "Soru hangi dildeyse o dilde cevap ver. "
                        "Diyalog geÃ§miÅŸini hatÄ±rla ve kaynaklara mutlaka (ğŸ“š Kaynak: Dosya AdÄ±) ÅŸeklinde atÄ±f yap. "
                        "Ã–ÄŸretici, ÅŸefkatli ve derinlemesine bilgi veren bir Ã¼slup kullan. "
                        "Mutlaka kaynaklara atÄ±f yap (Kaynak: Dosya AdÄ± ÅŸeklinde).\n"
                        "EÄŸer kaynaklarda bilgi kÄ±sÄ±tlÄ±ysa, genel Ä°slami bilgini kullanarak konuyu derinleÅŸtir ve 'KomÅŸuluk', 'Ahlak' gibi konularda Ã¶ÄŸretici bir ders verir gibi anlat.\n"
                        "YÄ±ldÄ±z (*) karakterini asla kullanma, metni dÃ¼z ve akÄ±cÄ± yaz.\n"
                        "CevaplarÄ±n sonunda kÄ±sa bir dua veya gÃ¼zel bir temenni ile bitir."
                    )
                    
                    full_query = f"{system_msg}\n\nGEÃ‡MÄ°Å:\n{gecmis_text}\n\nKAYNAKLAR:\n{baglam}\n\nSORU: {current_prompt}"
                    
                    res = client.models.generate_content(model=GUNCEL_MODEL, contents=full_query)
                    st.markdown(res.text)
                    st.session_state.messages.append({"role": "assistant", "content": res.text})
                    st.rerun()
                except Exception as e:
                    st.error(f"Hata: {e}")